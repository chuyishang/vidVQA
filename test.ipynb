{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['multiprocessing', 'path_pretrained_models', 'execute_code', 'dataset', 'gpt', 'llava', 'answerer', 'planner', 'retriever', 'extractor', 'evaluator', 'save', 'save_new_results', 'results_dir', 'use_cache', 'clear_cache', 'use_cached_codex', 'cached_codex_path', 'log_every', 'wandb', 'blip_half_precision', 'blip_v2_model_type', 'use_fixed_code', 'fixed_code_file'])\n",
      "./prompts/base_prompt.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 21:21:28.442431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-29 21:21:28.442470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-29 21:21:28.443719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-29 21:21:29.636947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataset import MyDataset\n",
    "import modules\n",
    "from vidobj import VideoObj\n",
    "import answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(data_path=\"/shared/shang/datasets/nextqa/videos/\",\n",
    "                    query_file=\"/shared/shang/datasets/nextqa/metadata/queries_2k.csv\",\n",
    "                    max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "video = VideoObj(item[\"video\"], item[\"query\"], item[\"possible_answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb971eca8764d1685755def0089a8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siglip = modules.SiglipModel(gpu_number=6, siglip_model_type=\"ViT-B-16-SigLIP\")\n",
    "llava = modules.LLAVA(gpu_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = modules.GPTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = answerer.Answerer(llava, llava, siglip, llm, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ans\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/vidVQA/answerer.py:85\u001b[0m, in \u001b[0;36mAnswerer.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_update()\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tries):\n\u001b[1;32m     87\u001b[0m         plan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanner\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/vidVQA/answerer.py:77\u001b[0m, in \u001b[0;36mAnswerer.init_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_update\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     start_frame, start_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_keyframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mimages, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mquestion)\n\u001b[1;32m     78\u001b[0m     start_sec, end_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mget_frame_from_second(start_frame), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo\u001b[38;5;241m.\u001b[39mget_frame_from_second(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo))\n\u001b[1;32m     79\u001b[0m     caption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractor\u001b[38;5;241m.\u001b[39mforward(start_image, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/vidVQA/answerer.py:64\u001b[0m, in \u001b[0;36mAnswerer.get_keyframe\u001b[0;34m(self, images, question)\u001b[0m\n\u001b[1;32m     62\u001b[0m siglip_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msiglip_prompt(question)\n\u001b[1;32m     63\u001b[0m keyframe_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mforward(siglip_prompt)\n\u001b[0;32m---> 64\u001b[0m index, keyframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_model\u001b[38;5;241m.\u001b[39mforward(images, keyframe_query)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\u001b[38;5;241m.\u001b[39mitem(), keyframe[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/vid_vqa/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/vidVQA/modules.py:231\u001b[0m, in \u001b[0;36mSiglipModel.forward\u001b[0;34m(self, images, queries, top_k)\u001b[0m\n\u001b[1;32m    227\u001b[0m raw_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(queries)):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#raw_images.append([indices[i][idx] for idx in range(3)])\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#indices = [indices[i][idx] for idx in range(top_k)] \u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     raw_images\u001b[38;5;241m.\u001b[39mappend([images[num] \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m [indices[i][idx]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(top_k)]])\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# TODO: also return the index\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices, raw_images\n",
      "File \u001b[0;32m~/vidVQA/modules.py:231\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m raw_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(queries)):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#raw_images.append([indices[i][idx] for idx in range(3)])\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#indices = [indices[i][idx] for idx in range(top_k)] \u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     raw_images\u001b[38;5;241m.\u001b[39mappend([images[num] \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m [indices[i][idx]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(top_k)]])\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# TODO: also return the index\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices, raw_images\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "ans.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vid_vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
