{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "jax.devices()\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 01:09:43.763518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 01:09:43.763570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 01:09:43.765198: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 01:09:44.908991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Pick your hero: (WHEN CHANGING THIS, RERUN IMAGE/TEXT EMBEDDING CELLS)\n",
    "# Give this cell 1-3mins.\n",
    "\n",
    "# VARIANT, RES = 'B/16', 224\n",
    "VARIANT, RES = 'B/16', 256\n",
    "# VARIANT, RES = 'B/16', 384\n",
    "# VARIANT, RES = 'B/16', 512\n",
    "# VARIANT, RES = 'L/16', 256\n",
    "# VARIANT, RES = 'L/16', 384\n",
    "# VARIANT, RES = 'So400m/14', 224\n",
    "# VARIANT, RES = 'So400m/14', 384\n",
    "# VARIANT, RES = 'B/16-i18n', 256\n",
    "\n",
    "CKPT, TXTVARIANT, EMBDIM, SEQLEN, VOCAB = {\n",
    "    ('B/16', 224): ('webli_en_b16_224_63724782.npz', 'B', 768, 64, 32_000),\n",
    "    ('B/16', 256): ('webli_en_b16_256_60500360.npz', 'B', 768, 64, 32_000),\n",
    "    ('B/16', 384): ('webli_en_b16_384_68578854.npz', 'B', 768, 64, 32_000),\n",
    "    ('B/16', 512): ('webli_en_b16_512_68580893.npz', 'B', 768, 64, 32_000),\n",
    "    ('L/16', 256): ('webli_en_l16_256_60552751.npz', 'L', 1024, 64, 32_000),\n",
    "    ('L/16', 384): ('webli_en_l16_384_63634585.npz', 'L', 1024, 64, 32_000),\n",
    "    ('So400m/14', 224): ('webli_en_so400m_224_57633886.npz', 'So400m', 1152, 16, 32_000),\n",
    "    ('So400m/14', 384): ('webli_en_so400m_384_58765454.npz', 'So400m', 1152, 64, 32_000),\n",
    "    ('B/16-i18n', 256): ('webli_i18n_b16_256_66117334.npz', 'B', 768, 64, 250_000),\n",
    "}[VARIANT, RES]\n",
    "\n",
    "file_path = f\"./models/siglip/{CKPT}\"\n",
    "# Check if the file exists\n",
    "if not os.path.isfile(file_path):\n",
    "    print(\"downloading file\")\n",
    "    # If the file doesn't exist, copy it from Google Cloud Storage\n",
    "    subprocess.run(['gsutil', 'cp', f'gs://big_vision/siglip/{CKPT}', file_path], check=True)\n",
    "else:\n",
    "    print(\"file exists\")\n",
    "\n",
    "sys.path.append('/home/shang/vidVQA/models/big_vision/')\n",
    "import big_vision.models.proj.image_text.two_towers as model_mod\n",
    "\n",
    "model_cfg = ml_collections.ConfigDict()\n",
    "model_cfg.image_model = 'vit'  # TODO(lbeyer): remove later, default\n",
    "model_cfg.text_model = 'proj.image_text.text_transformer'  # TODO(lbeyer): remove later, default\n",
    "model_cfg.image = dict(variant=VARIANT, pool_type='map')\n",
    "model_cfg.text = dict(variant=TXTVARIANT, vocab_size=VOCAB)\n",
    "model_cfg.out_dim = (None, EMBDIM)  # (image_out_dim, text_out_dim)\n",
    "model_cfg.bias_init = -10.0\n",
    "model_cfg.temperature_init = 10.0\n",
    "\n",
    "model = model_mod.Model(**model_cfg)\n",
    "\n",
    "# Using `init_params` is slower but will lead to `load` below performing sanity-checks.\n",
    "# init_params = jax.jit(model.init, backend=\"cpu\")(jax.random.PRNGKey(42), jnp.zeros([1, RES, RES, 3], jnp.float32), jnp.zeros([1, SEQLEN], jnp.int32))['params']\n",
    "init_params = None  # Faster but bypasses loading sanity-checks.\n",
    "\n",
    "params = model_mod.load(init_params, f'./models/siglip/{CKPT}', model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shang/miniconda3/envs/vid_vqa/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/shang/miniconda3/envs/vid_vqa/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import big_vision.pp.builder as pp_builder\n",
    "import big_vision.pp.ops_general\n",
    "import big_vision.pp.ops_image\n",
    "import big_vision.pp.ops_text\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'apple-ipod.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shang/vidVQA/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#@title Load and embed images\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m images \u001b[39m=\u001b[39m [PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mapple-ipod.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mapple-blank.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcold_drink.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mhot_drink.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcaffeine.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msiglip.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mauthors.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrobosign.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcow_beach.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcow_beach2.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmountain_view.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m pp_img \u001b[39m=\u001b[39m pp_builder\u001b[39m.\u001b[39mget_preprocess_fn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresize(\u001b[39m\u001b[39m{\u001b[39;00mRES\u001b[39m}\u001b[39;00m\u001b[39m)|value_range(-1, 1)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([pp_img({\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marray(\u001b[39m\"\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m image)})[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images])\n",
      "\u001b[1;32m/home/shang/vidVQA/testing.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#@title Load and embed images\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m images \u001b[39m=\u001b[39m [PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mapple-ipod.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mapple-blank.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcold_drink.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mhot_drink.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcaffeine.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msiglip.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mauthors.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrobosign.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcow_beach.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcow_beach2.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmountain_view.jpg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m pp_img \u001b[39m=\u001b[39m pp_builder\u001b[39m.\u001b[39mget_preprocess_fn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresize(\u001b[39m\u001b[39m{\u001b[39;00mRES\u001b[39m}\u001b[39;00m\u001b[39m)|value_range(-1, 1)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcharybdis.ist.berkeley.edu/home/shang/vidVQA/testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([pp_img({\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marray(\u001b[39m\"\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m image)})[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images])\n",
      "File \u001b[0;32m~/miniconda3/envs/vid_vqa/lib/python3.11/site-packages/PIL/Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3242\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3243\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3244\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'apple-ipod.jpg'"
     ]
    }
   ],
   "source": [
    "#@title Load and embed images\n",
    "images = [PIL.Image.open(\"./data/\" + fname) for fname in (\n",
    "    'apple-ipod.jpg',\n",
    "    'apple-blank.jpg',\n",
    "    'cold_drink.jpg',\n",
    "    'hot_drink.jpg',\n",
    "    'caffeine.jpg',\n",
    "    'siglip.jpg',\n",
    "    'authors.jpg',\n",
    "    'robosign.jpg',\n",
    "    'cow_beach.jpg',\n",
    "    'cow_beach2.jpg',\n",
    "    'mountain_view.jpg',\n",
    ")]\n",
    "\n",
    "pp_img = pp_builder.get_preprocess_fn(f'resize({RES})|value_range(-1, 1)')\n",
    "imgs = np.array([pp_img({'image': np.array(\"./data/\"+ image)})['image'] for image in images])\n",
    "zimg, _, out = model.apply({'params': params}, imgs, None)\n",
    "\n",
    "print(imgs.shape, zimg.shape)\n",
    "\n",
    "#@title Tokenize and embed texts\n",
    "\n",
    "texts = [\n",
    "    'an apple',\n",
    "    'a picture of an apple',\n",
    "    'an ipod',\n",
    "    'granny smith',\n",
    "    'an apple with a note saying \"ipod\"',\n",
    "    'a cold drink on a hot day',\n",
    "    'a hot drink on a cold day',\n",
    "    'a photo of a cold drink on a hot day',\n",
    "    'a photo of a hot drink on a cold day',\n",
    "    #\n",
    "    'a photo of two guys in need of caffeine',\n",
    "    'a photo of two guys in need of water',\n",
    "    'a photo of the SigLIP authors',\n",
    "    'a photo of a rock band',\n",
    "    'a photo of researchers at Google Brain',\n",
    "    'a photo of researchers at OpenAI',\n",
    "    #\n",
    "    'a robot on a sign',\n",
    "    'a photo of a robot on a sign',\n",
    "    'an empty street',\n",
    "    'autumn in Toronto',\n",
    "    'a photo of autumn in Toronto',\n",
    "    'a photo of Toronto in autumn',\n",
    "    'a photo of Toronto in summer',\n",
    "    'autumn in Singapore',\n",
    "    #\n",
    "    'cow',\n",
    "    'a cow in a tuxedo',\n",
    "    'a cow on the beach',\n",
    "    'a cow in the prairie',\n",
    "    #\n",
    "    'the real mountain view',\n",
    "    'Zürich',\n",
    "    'San Francisco',\n",
    "    'a picture of a laptop with the lockscreen on, a cup of cappucino, salt and pepper grinders. The view through the window reveals lake Zürich and the Alps in the background of the city.',\n",
    "]\n",
    "\n",
    "TOKENIZERS = {\n",
    "    32_000: 'c4_en',\n",
    "    250_000: 'mc4',\n",
    "}\n",
    "pp_txt = pp_builder.get_preprocess_fn(f'tokenize(max_len={SEQLEN}, model=\"{TOKENIZERS[VOCAB]}\", eos=\"sticky\", pad_value=1, inkey=\"text\")')\n",
    "txts = np.array([pp_txt({'text': text})['labels'] for text in texts])\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "_, ztxt, out = model.apply({'params': params}, None, txts)\n",
    "\n",
    "print(txts.shape, ztxt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mnian                         \u001b[m  Thu Nov 16 22:24:16 2023  \u001b[1m\u001b[30m535.86.10\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA TITAN RTX          \u001b[m |\u001b[31m 34°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m24139\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m24124M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m11M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA TITAN RTX          \u001b[m |\u001b[31m 44°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9536\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m166M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 33°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  172\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m158M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 33°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  172\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m158M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA TITAN RTX          \u001b[m |\u001b[31m 33°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  180\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m166M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 31°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  172\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m158M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 31°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  172\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m158M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA TITAN RTX          \u001b[m |\u001b[31m 32°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  180\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m166M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[8]\u001b[m \u001b[34mNVIDIA TITAN RTX          \u001b[m |\u001b[31m 32°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  180\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m166M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n",
      "\u001b[36m[9]\u001b[m \u001b[34mNVIDIA GeForce RTX 2080 Ti\u001b[m |\u001b[31m 31°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  172\u001b[m / \u001b[33m11264\u001b[m MB | \u001b[1m\u001b[30mshang\u001b[m(\u001b[33m158M\u001b[m) \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m10M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidVQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
