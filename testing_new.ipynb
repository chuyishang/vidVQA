{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n",
    "import decord\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(video_path, num_frames):\n",
    "        # If fixed width and height are required, VideoReader takes width and height as arguments.\n",
    "        video_reader = decord.VideoReader(str(video_path), num_threads=1, ctx=cpu(0))\n",
    "        decord.bridge.set_bridge('torch')\n",
    "        vlen = len(video_reader)\n",
    "        original_fps = video_reader.get_avg_fps()\n",
    "        num_frames = int(vlen * self.fps / original_fps)\n",
    "        # num_frames = min(self.max_num_frames, num_frames)\n",
    "        frame_idxs = np.linspace(0, vlen, num_frames, endpoint=False).astype(np.int)\n",
    "        video = video_reader.get_batch(frame_idxs).byte()\n",
    "        video = video.permute(0, 3, 1, 2)\n",
    "        return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features shape:  torch.Size([4, 1152]) Text features shape:  torch.Size([1, 1152])\n",
      "[('robosign.jpg', 0.0), ('cow_beach.jpg', 0.001), ('cow_beach2.jpg', 0.99), ('mountain_view.jpg', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, preprocess = create_model_from_pretrained('hf-hub:timm/ViT-SO400M-14-SigLIP-384')\n",
    "model = model.to(device)\n",
    "preprocess = preprocess\n",
    "tokenizer = get_tokenizer('hf-hub:timm/ViT-SO400M-14-SigLIP-384')\n",
    "\n",
    "filenames = [\n",
    "    'apple-ipod.jpg',\n",
    "    'apple-blank.jpg',\n",
    "    'cold_drink.jpg',\n",
    "    'hot_drink.jpg',\n",
    "    'caffeine.jpg',\n",
    "    'siglip.jpg',\n",
    "    'authors.jpg',\n",
    "    'robosign.jpg',\n",
    "    'cow_beach.jpg',\n",
    "    'cow_beach2.jpg',\n",
    "    'mountain_view.jpg',]\n",
    "\n",
    "#@title Load and embed images\n",
    "images = [Image.open(\"./data/\" + fname) for fname in (filenames)]\n",
    "\n",
    "labels_list = [\"a cow in a tuxedo\"]\n",
    "image_stack = torch.stack([preprocess(image) for image in images]).to(device)\n",
    "text = tokenizer(labels_list, context_length=model.context_length).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image_stack)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features = F.normalize(image_features, dim=-1)\n",
    "    text_features = F.normalize(text_features, dim=-1)\n",
    "    print(\"Image features shape: \", image_features.shape, \"Text features shape: \", text_features.shape)\n",
    "\n",
    "    text_probs = torch.sigmoid(text_features @ image_features.T * model.logit_scale.exp() + model.logit_bias)\n",
    "\n",
    "zipped_list = list(zip(filenames, [round(p.item(), 3) for p in text_probs[0]]))\n",
    "print(zipped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(self, video_path):\n",
    "        # If fixed width and height are required, VideoReader takes width and height as arguments.\n",
    "        video_reader = decord.VideoReader(str(video_path), num_threads=1, ctx=cpu(0))\n",
    "        decord.bridge.set_bridge('torch')\n",
    "        vlen = len(video_reader)\n",
    "        original_fps = video_reader.get_avg_fps()\n",
    "        num_frames = int(vlen * self.fps / original_fps)\n",
    "        num_frames = min(self.max_num_frames, num_frames)\n",
    "        frame_idxs = np.linspace(0, vlen, num_frames, endpoint=False).astype(np.int)\n",
    "        video = video_reader.get_batch(frame_idxs).byte()\n",
    "        video = video.permute(0, 3, 1, 2)\n",
    "        return video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vid_vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
